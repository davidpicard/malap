{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP DT\n",
    "\n",
    "_Correction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will use the [MNIST dataset (~15Mo)](https://educnet.enpc.fr/mod/resource/view.php?id=44975). It consists of 28x28 images (loaded as a 784 vector) and the associated label for training, validation and test sets. \n",
    "\n",
    "The following code loads all samples from the MNIST archive into several arrays, then displays the first sample from the training set as an image. We will limit ourselves to the first 1000 samples of train and 1000 samples of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, val_set, test_set = pickle.load(f, encoding='latin1') # python 3\n",
    "# train_set, val_set, test_set = cPickle.load(f) # python 2\n",
    "f.close()\n",
    "train_data=train_set[0][0:1000, :]\n",
    "train_labels=train_set[1][0:1000]\n",
    "val_data=val_set[0][0:1000, :]\n",
    "val_labels=val_set[1][0:1000]\n",
    "N_train=train_data.shape[0]\n",
    "N_val=val_data.shape[0]\n",
    "# check data makes sense\n",
    "plt.imshow(train_data[0,:].reshape(28,28))\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a randomized Decision Tree\n",
    "\n",
    "#### Q1. Implement the code of a randomized Decision Tree of maximal depth $d$ in the following class, using the $0-1$ loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "takes arguements \n",
    "y_pred: prediction\n",
    "y_true: true labels\n",
    "weights: weights for each example\n",
    "'''\n",
    "@jax.jit\n",
    "def zeroOneLoss(y_pred, y_true, weights):\n",
    "    return (weights * (y_pred != y_true)).sum(axis=0)/(1e-12+weights.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "takes arguments\n",
    "X: training samples\n",
    "y: training labels\n",
    "dim: dimension to use\n",
    "w: weight associated to each example (can be True/False or 1/0 to remove some examples)\n",
    "'''\n",
    "@jax.jit\n",
    "def findBestTh(X, y, dim, w):\n",
    "    labels = jax.nn.one_hot(y, num_classes=10).squeeze() # dim n x 10\n",
    "    C0 =  zeroOneLoss((w[:,None]*labels).mean(axis=0).argmax(), y, w)\n",
    "\n",
    "    th = X[:,dim].sort()[1:]-1e-7 # dim n-1\n",
    "    ind = (X[:,dim, None]<th[None,:]) # dim n x n-1\n",
    "    labels = labels[:,None,:] # dim n x 1 x 10\n",
    "    ind2 = ind[:,:,None] # dim n x n-1 x 1\n",
    "    y = y[:, None] # dim n x 1\n",
    "    w1 = w[:,None] # dim n x 1\n",
    "    w2 = w[:,None,None] # dim n x 1 x 1\n",
    "\n",
    "    # left\n",
    "    y_pred_l = (labels * (ind2*w2)).sum(axis=0).argmax(axis=1) # de dim n-1 puisqu'on a réduit sur 0 et 2 (devenu 1)\n",
    "    Cl = zeroOneLoss(y_pred_l[None, :], y, weights=(ind)*w1)\n",
    "    nl = (w1*ind).sum(axis=0) # nb valides x nb à gauche\n",
    "    # right\n",
    "    y_pred_r = (labels * (~ind2)*w2).sum(axis=0).argmax(axis=1) # de dim n-1 puisqu'on a réduit sur 0 et 2 (devenu 1)\n",
    "    Cr =  zeroOneLoss(y_pred_r[None, :], y, weights=(~ind)*w1)\n",
    "    nr = (w1*~ind).sum(axis=0) # nb valides x nb à droite\n",
    "\n",
    "\n",
    "    C = C0 - (nl*Cl + nr*Cr)/(1e-12+nl+nr)\n",
    "\n",
    "    #print('G: {} C0: {} C: {} Cl: {} Cr: {} nl: {} nr: {}'.format(C.max(), C0, C, Cl, Cr, nl, nr))\n",
    "    m = C.argmax()\n",
    "    return C[m], th[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanAllDim = jax.vmap(findBestTh, (None, None, 0, None), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomizedDT():\n",
    "    def __init__(self, percent_dimension=1.0, max_depth=8, max_size=20, verbose=False):\n",
    "        self.percent_dimension = percent_dimension\n",
    "        self.max_depth = max_depth\n",
    "        if max_depth > 0:\n",
    "            self.left = RandomizedDT(percent_dimension, max_depth=max_depth-1, max_size=max_size, verbose=verbose)\n",
    "            self.right = RandomizedDT(percent_dimension, max_depth=max_depth-1, max_size=max_size, verbose=verbose)\n",
    "        self.label = None\n",
    "        self.max_size = max_size\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    '''\n",
    "    train this decision tree on a random subset of dimensions (columns) of X with a maximum depth\n",
    "    '''\n",
    "    def fit(self, X, y, w=None):\n",
    "        X = jnp.array(X)\n",
    "        y = jnp.array(y)\n",
    "        if w is None:\n",
    "            w = jnp.ones(len(X))\n",
    "        if self.verbose:\n",
    "            print('depth {} X: {} y: {} w: {}'.format(self.max_depth, X.shape, y.shape, w.sum()))\n",
    "        label = jax.nn.one_hot(y, num_classes=10)\n",
    "        if self.max_depth <= 0 or w.sum() <= self.max_size or (w[:,None]*label).sum(axis=0).max() == w.sum():\n",
    "            if self.verbose:\n",
    "                print('found label: {} {}'.format((w[:,None]*label).sum(axis=0), w.sum()))\n",
    "            self.label = (w[:, None]*label).mean(axis=0).argmax()\n",
    "            return\n",
    "        d = X.shape[1]\n",
    "        r = jnp.array(np.random.permutation(d)[0:int(d*self.percent_dimension)])\n",
    "\n",
    "        s = X[:,r].std(axis=0)\n",
    "        r = r[s>0]     \n",
    "        s = X[:,r].std(axis=0)\n",
    "        r = r[s.argsort()[::-1]]\n",
    "        gains = []\n",
    "        thres = []\n",
    "        for i in r:\n",
    "            #g, t = scanAllDim(X, y, jnp.array(r[i:min(i+20, len(r))]), w)\n",
    "            g, t = findBestTh(X, y, i, w)\n",
    "            gains.append(g)\n",
    "            thres.append(t)\n",
    "        \n",
    "        gains = jnp.array(gains)\n",
    "        d = gains.argmax()\n",
    "        best_gain = gains[d]\n",
    "        \n",
    "        if best_gain <= 0:\n",
    "            self.label = (w[:, None]*label).mean(axis=0).argmax()\n",
    "            return\n",
    "        \n",
    "        self.label = None\n",
    "        best_dim = r[d]\n",
    "        self.dim = best_dim\n",
    "        best_th = thres[d]\n",
    "        self.th = best_th\n",
    "        if self.verbose:\n",
    "            print('found dim: {} theta: {} gain: {}'.format(best_dim, best_th, best_gain))\n",
    "        ind = X[:, best_dim] < best_th\n",
    "        if self.verbose:\n",
    "            print('fitting left')\n",
    "        self.left.fit(X, y, w*ind)\n",
    "        if self.verbose:\n",
    "            print('fitting right')\n",
    "        self.right.fit(X, y, w*~ind)\n",
    "        return       \n",
    "    \n",
    "    '''\n",
    "    predict the set of samples\n",
    "    '''\n",
    "    def predict(self, X):\n",
    "        if self.label is not None:\n",
    "            return self.label * jnp.ones(len(X))\n",
    "        return jnp.concatenate([self.left.predict([x]) if x[self.dim] < self.th else self.right.predict([x]) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try on the training set reduced to digits 0 and 1 with all dimensions to check that our code works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 6 X: (213, 784) y: (213,) w: 213.0\n",
      "found dim: 96 theta: 0.5507811307907104 gain: 0.44600939750671387\n",
      "fitting left\n",
      "depth 5 X: (213, 784) y: (213,) w: 99.0\n",
      "found dim: 47 theta: 0.9843748807907104 gain: 0.010101010091602802\n",
      "fitting left\n",
      "depth 4 X: (213, 784) y: (213,) w: 98.0\n",
      "found dim: 576 theta: 0.16406239569187164 gain: 0.010204081423580647\n",
      "fitting left\n",
      "depth 3 X: (213, 784) y: (213,) w: 97.0\n",
      "found label: [97.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 97.0\n",
      "fitting right\n",
      "depth 3 X: (213, 784) y: (213,) w: 1.0\n",
      "found label: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1.0\n",
      "fitting right\n",
      "depth 4 X: (213, 784) y: (213,) w: 1.0\n",
      "found label: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1.0\n",
      "fitting right\n",
      "depth 5 X: (213, 784) y: (213,) w: 114.0\n",
      "found label: [  0. 114.   0.   0.   0.   0.   0.   0.   0.   0.] 114.0\n",
      "done in 1.003629446029663\n",
      "0.0\n",
      "0.024154589\n"
     ]
    }
   ],
   "source": [
    "x_train_01 = train_data[jnp.where(train_labels < 2), ...].squeeze()\n",
    "y_train_01 = train_labels[jnp.where(train_labels < 2)].squeeze()\n",
    "x_val_01 = val_data[jnp.where(val_labels < 2), ...].squeeze()\n",
    "y_val_01 = val_labels[jnp.where(val_labels < 2)].squeeze()\n",
    "\n",
    "r = jnp.array(np.random.permutation(784))\n",
    "\n",
    "x_train_01 = x_train_01[:, r[0:784]]\n",
    "x_val_01 = x_val_01[:, r[0:784]]\n",
    "\n",
    "dt = RandomizedDT(percent_dimension=1.0, max_depth=6, max_size=5, verbose=True)\n",
    "start_time = time.time()\n",
    "dt.fit(x_train_01, y_train_01)\n",
    "print('done in {}'.format(time.time() - start_time))\n",
    "y_hat = dt.predict(x_train_01)\n",
    "err = zeroOneLoss(y_hat, y_train_01, jnp.ones(len(y_train_01)))\n",
    "print(err)\n",
    "y_hat = dt.predict(x_val_01)\n",
    "err = zeroOneLoss(y_hat, y_val_01, jnp.ones(len(y_val_01)))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1. 1. 0. 1. 1. 0. 0.] [0 1 1 1 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(dt.predict(x_train_01[0:10, :]), y_train_01[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 4 X: (1000, 784) y: (1000,) w: 1000.0\n",
      "found dim: 74 theta: 0.9335936307907104 gain: 0.10199999809265137\n",
      "fitting left\n",
      "depth 3 X: (1000, 784) y: (1000,) w: 619.0\n",
      "found dim: 133 theta: 0.0039061501156538725 gain: 0.13731825351715088\n",
      "fitting left\n",
      "depth 2 X: (1000, 784) y: (1000,) w: 366.0\n",
      "found dim: 257 theta: 0.011718650348484516 gain: 0.1666666865348816\n",
      "fitting left\n",
      "depth 1 X: (1000, 784) y: (1000,) w: 185.0\n",
      "found dim: 586 theta: 0.0039061501156538725 gain: 0.07567569613456726\n",
      "fitting left\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 137.0\n",
      "found label: [ 0.  1.  3.  7.  6.  3.  3. 95.  1. 18.] 137.0\n",
      "fitting right\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 48.0\n",
      "found label: [ 0.  4.  8. 14.  2.  6.  6.  0.  6.  2.] 48.0\n",
      "fitting right\n",
      "depth 1 X: (1000, 784) y: (1000,) w: 181.0\n",
      "found dim: 640 theta: 0.27734366059303284 gain: 0.16022098064422607\n",
      "fitting left\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 101.0\n",
      "found label: [ 2.  0.  3.  0. 69.  0. 16.  3.  2.  6.] 101.0\n",
      "fitting right\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 80.0\n",
      "found label: [ 7.  0.  4.  7.  3.  6. 11.  8.  2. 32.] 80.0\n",
      "fitting right\n",
      "depth 2 X: (1000, 784) y: (1000,) w: 253.0\n",
      "found dim: 172 theta: 0.19140614569187164 gain: 0.13833993673324585\n",
      "fitting left\n",
      "depth 1 X: (1000, 784) y: (1000,) w: 169.0\n",
      "found dim: 208 theta: 0.0039061501156538725 gain: 0.18934911489486694\n",
      "fitting left\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 105.0\n",
      "found label: [87.  0.  2.  1.  0.  8.  6.  0.  0.  1.] 105.0\n",
      "fitting right\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 64.0\n",
      "found label: [ 1.  1.  4. 20.  0. 33.  0.  0.  4.  1.] 64.0\n",
      "fitting right\n",
      "depth 1 X: (1000, 784) y: (1000,) w: 84.0\n",
      "found label: [ 0.  0. 35.  1.  3.  5. 30.  3.  4.  3.] 84.0\n",
      "fitting right\n",
      "depth 3 X: (1000, 784) y: (1000,) w: 381.0\n",
      "found dim: 458 theta: 0.0039061501156538725 gain: 0.13648289442062378\n",
      "fitting left\n",
      "depth 2 X: (1000, 784) y: (1000,) w: 219.0\n",
      "found dim: 58 theta: 0.007812399882823229 gain: 0.12328764796257019\n",
      "fitting left\n",
      "depth 1 X: (1000, 784) y: (1000,) w: 176.0\n",
      "found dim: 366 theta: 0.06249989941716194 gain: 0.10795456171035767\n",
      "fitting left\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 125.0\n",
      "found label: [  0. 106.   9.   0.   0.   0.   1.   4.   5.   0.] 125.0\n",
      "fitting right\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 51.0\n",
      "found label: [ 0.  1.  1. 20.  6.  0.  3.  4.  2. 14.] 51.0\n",
      "fitting right\n",
      "depth 1 X: (1000, 784) y: (1000,) w: 43.0\n",
      "found label: [ 0.  1. 28.  4.  2.  1.  0.  0.  7.  0.] 43.0\n",
      "fitting right\n",
      "depth 2 X: (1000, 784) y: (1000,) w: 162.0\n",
      "found dim: 567 theta: 0.011718650348484516 gain: 0.12962967157363892\n",
      "fitting left\n",
      "depth 1 X: (1000, 784) y: (1000,) w: 54.0\n",
      "found label: [ 0.  1.  1. 18.  4. 21.  0.  0.  0.  9.] 54.0\n",
      "fitting right\n",
      "depth 1 X: (1000, 784) y: (1000,) w: 108.0\n",
      "found dim: 570 theta: 0.007812399882823229 gain: 0.12962964177131653\n",
      "fitting left\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 75.0\n",
      "found label: [ 0.  1.  0.  0.  4.  4.  1.  0. 51. 14.] 75.0\n",
      "fitting right\n",
      "depth 0 X: (1000, 784) y: (1000,) w: 33.0\n",
      "found label: [ 0.  0.  1.  1.  6.  5. 17.  0.  3.  0.] 33.0\n",
      "done in 175.12984466552734\n",
      "0.392\n",
      "0.479\n"
     ]
    }
   ],
   "source": [
    "r = np.random.permutation(784)\n",
    "\n",
    "x_train = train_data[:, r[0:784]]\n",
    "x_val = val_data[:, r[0:784]]\n",
    "\n",
    "\n",
    "dt = RandomizedDT(percent_dimension=1.0, max_depth=4, max_size=100, verbose=True)\n",
    "start_time = time.time()\n",
    "dt.fit(x_train, train_labels)\n",
    "print('done in {}'.format(time.time() - start_time))\n",
    "y_hat = dt.predict(x_train)\n",
    "err = zeroOneLoss(y_hat, train_labels, jnp.ones(len(train_labels)))\n",
    "print(err)\n",
    "y_hat = dt.predict(x_val)\n",
    "err = zeroOneLoss(y_hat, val_labels, jnp.ones(len(val_labels)))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. Use cross-validation on the full digit dataset (0-9) to select a reasonnable depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 2\n",
      "found label: [ 8.  1.  8.  3. 19.  2. 10. 47.  2. 10.] 110.0\n",
      "found label: [39.  0.  9.  8.  0. 11.  9.  1.  0.  1.] 78.0\n",
      "found label: [ 0. 59. 15.  6.  5. 12.  3.  2. 37. 10.] 149.0\n",
      "found label: [ 3.  0. 21. 35. 26. 22. 22.  3.  8. 23.] 163.0\n",
      "done in 2.3534975051879883\n",
      "found label: [ 7.  1.  5.  1. 22.  5. 19. 52.  3.  9.] 124.0\n",
      "found label: [38.  0.  6.  4.  0. 10.  8.  2.  1.  2.] 71.0\n",
      "found label: [ 0. 55. 16.  3.  4. 16.  5.  2. 33. 11.] 145.0\n",
      "found label: [ 2.  1. 21. 39. 24. 17. 16.  4.  7. 29.] 160.0\n",
      "done in 1.3963041305541992\n",
      "found label: [33.  0.  2.  0.  1.  6.  1.  4.  0.  2.] 49.0\n",
      "found label: [ 0. 64. 10.  4.  3. 12.  8.  1. 25.  5.] 132.0\n",
      "found label: [ 4.  1. 22. 25. 50. 13. 23. 12. 13. 19.] 182.0\n",
      "found label: [ 9.  0. 10. 17.  0. 12. 17. 39.  5. 28.] 137.0\n",
      "done in 1.416381597518921\n",
      "found label: [ 7.  0.  5.  4. 24.  2. 16. 48.  1. 15.] 122.0\n",
      "found label: [33.  1.  8.  3.  0.  8. 10.  2.  0.  2.] 67.0\n",
      "found label: [ 0. 56. 21.  2.  1. 15.  5.  2. 28.  5.] 135.0\n",
      "found label: [ 0.  4. 16. 35. 26. 23. 23.  3. 14. 32.] 176.0\n",
      "done in 1.1321704387664795\n",
      "found label: [ 9.  0.  7.  4. 22.  3. 17. 49.  3. 12.] 126.0\n",
      "found label: [47.  1.  9.  4.  1.  7.  9.  0.  1.  0.] 79.0\n",
      "found label: [ 2. 60. 37. 29.  7. 11.  8.  4. 14.  3.] 175.0\n",
      "found label: [ 1.  1.  2.  7. 21. 18. 11.  0. 25. 34.] 120.0\n",
      "done in 1.1399033069610596\n",
      "mean: 0.8880000114440918 stddev: 0.041182518005371094\n",
      "depth 3\n",
      "found label: [ 0.  1.  2.  0. 34.  0. 16. 10.  0.  3.] 66.0\n",
      "found label: [ 6.  1.  7.  1.  4.  2.  8. 46.  0. 21.] 96.0\n",
      "found label: [30.  1.  3.  1.  0.  1.  0.  1.  0.  0.] 37.0\n",
      "found label: [ 2.  0. 21.  0.  1.  3.  5.  0.  2.  1.] 35.0\n",
      "found label: [ 0. 53. 12.  5.  3.  1.  1.  2.  8.  0.] 85.0\n",
      "found label: [ 0.  2.  0.  3.  4.  3.  1.  1.  6. 16.] 36.0\n",
      "found label: [10.  0.  2.  7.  6. 22.  4.  1.  2.  7.] 61.0\n",
      "found label: [ 0.  4.  5. 18.  4. 13.  7.  0. 31.  2.] 84.0\n",
      "done in 2.752938985824585\n",
      "found label: [37.  0.  1.  4.  0.  4.  1.  3.  0.  0.] 50.0\n",
      "found label: [0. 0. 1. 1. 2. 0. 4. 5. 1. 3.] 17.0\n",
      "found label: [ 1. 61. 11.  2.  1.  8.  8.  0.  8.  5.] 105.0\n",
      "found label: [ 0.  0.  3.  1.  0.  6.  1.  1. 24.  0.] 36.0\n",
      "found label: [ 0.  0.  3.  0. 53.  5. 16.  6.  5.  3.] 91.0\n",
      "found label: [ 0.  0. 12. 16.  0.  2.  0.  0.  4.  0.] 34.0\n",
      "found label: [ 4.  1.  5.  2.  3.  8.  8. 42.  0.  5.] 78.0\n",
      "found label: [ 4.  0.  9. 10.  2. 12. 10.  3.  6. 33.] 89.0\n",
      "done in 2.976572036743164\n",
      "found label: [ 0.  0.  5.  2. 21.  1.  6.  8.  2.  3.] 48.0\n",
      "found label: [ 5.  0.  2.  4.  3.  4.  0. 40.  0.  7.] 65.0\n",
      "found label: [42.  0.  0.  4.  0.  9.  1.  0.  0.  1.] 57.0\n",
      "found label: [ 2.  0.  7.  0.  2.  1. 14.  5.  1.  1.] 33.0\n",
      "found label: [ 0. 53. 13.  3.  1.  7.  6.  1.  7.  6.] 97.0\n",
      "found label: [ 0.  0.  2.  0.  2.  4.  0.  1. 17.  0.] 26.0\n",
      "found label: [ 2.  3. 22. 36. 10. 12.  6.  3.  3.  5.] 102.0\n",
      "found label: [ 0.  1.  2.  3. 15.  7.  9.  1.  8. 26.] 72.0\n",
      "done in 3.4658191204071045\n",
      "found label: [1. 0. 2. 2. 1. 3. 3. 6. 0. 3.] 21.0\n",
      "found label: [32.  0.  1.  4.  1.  3.  2.  0.  1.  0.] 44.0\n",
      "found label: [ 0. 55. 12.  6.  1.  8.  6.  2.  9.  3.] 102.0\n",
      "found label: [ 0.  1.  3.  2.  2.  2.  0.  0. 23.  1.] 34.0\n",
      "found label: [ 0.  1.  4.  5. 51.  7. 20.  7.  3. 16.] 114.0\n",
      "found label: [ 0.  0. 17. 20.  0. 11.  4.  1.  6.  0.] 59.0\n",
      "found label: [ 7.  0.  3.  3.  0.  3.  6. 38.  1.  3.] 64.0\n",
      "found label: [ 1.  0.  3. 11.  2. 12.  6.  2.  7. 18.] 62.0\n",
      "done in 3.2942006587982178\n",
      "found label: [ 3.  1.  1.  0. 37.  2. 15.  4.  0.  2.] 65.0\n",
      "found label: [10.  0. 19.  0.  1.  1.  3.  1.  0.  1.] 36.0\n",
      "found label: [ 4.  2.  5.  1.  4.  0.  4. 50.  1. 20.] 91.0\n",
      "found label: [23.  0.  7.  2.  0.  5.  8.  1.  2.  0.] 48.0\n",
      "found label: [ 0. 56. 14.  2.  2.  7.  3.  1.  8. 15.] 108.0\n",
      "found label: [ 1.  0.  0.  2.  0.  3.  0.  0. 24.  0.] 30.0\n",
      "found label: [ 8.  0.  6. 33.  2.  5.  9.  1.  0.  0.] 64.0\n",
      "found label: [ 3.  0.  0.  5.  7. 12.  5.  3.  7. 16.] 58.0\n",
      "done in 3.3008923530578613\n",
      "mean: 0.9120000004768372 stddev: 0.05741080269217491\n",
      "depth 4\n",
      "found label: [ 0.  0.  0.  0. 28.  1.  3.  3.  0.  4.] 39.0\n",
      "found label: [1. 0. 0. 0. 1. 1. 0. 3. 0. 0.] 6.0\n",
      "found label: [ 6.  1.  2.  1.  1.  2.  1. 47.  0.  6.] 67.0\n",
      "found label: [ 0.  0.  2.  2.  2.  0.  1.  1.  1. 13.] 22.0\n",
      "found label: [ 1.  1.  1.  1.  2.  2. 21.  0.  1.  0.] 30.0\n",
      "found label: [1. 0. 8. 0. 0. 0. 0. 0. 0. 1.] 10.0\n",
      "found label: [25.  1.  2.  1.  0.  0.  0.  0.  0.  0.] 29.0\n",
      "found label: [ 2.  0. 11.  0.  1.  1.  0.  0.  0.  2.] 17.0\n",
      "found label: [ 1. 65.  9.  3.  0.  3.  1.  2.  1.  1.] 86.0\n",
      "found label: [ 0.  0.  0.  2.  1.  6.  6.  0.  5. 10.] 30.0\n",
      "found label: [0. 1. 1. 0. 0. 4. 0. 0. 0. 0.] 6.0\n",
      "found label: [ 0.  0.  2.  3.  0.  1.  0.  0. 20.  0.] 26.0\n",
      "found label: [ 7.  1.  0. 41.  3.  6.  1.  0.  1.  5.] 65.0\n",
      "found label: [0. 0. 0. 0. 9. 7. 0. 0. 2. 6.] 24.0\n",
      "found label: [ 2.  0.  0.  0.  1.  4. 13.  1.  6.  2.] 29.0\n",
      "found label: [1. 0. 9. 0. 0. 3. 1. 0. 0. 0.] 14.0\n",
      "done in 6.681536436080933\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5d1ba0cc08f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m550\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done in {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeroOneLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-663d746a7a34>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fitting left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fitting right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-663d746a7a34>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, w)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mgains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mthres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Archives/Code/pytorch_env/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx)\u001b[0m\n\u001b[1;32m   4245\u001b[0m   \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4246\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4247\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4249\u001b[0m \u001b[0;31m# TODO(phawkins): re-enable jit after fixing excessive recompilation for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Archives/Code/pytorch_env/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx)\u001b[0m\n\u001b[1;32m   4252\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4253\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_static_and_dynamic_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4254\u001b[0;31m   \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shared with _scatter_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4255\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Archives/Code/pytorch_env/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   4473\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4474\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4475\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4476\u001b[0m         \u001b[0mgather_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4477\u001b[0m         \u001b[0mslice_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Archives/Code/pytorch_env/lib/python3.7/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(arr, shape)\u001b[0m\n\u001b[1;32m   1674\u001b[0m     \u001b[0mnew_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlead\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[0mkept_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_in_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Archives/Code/pytorch_env/lib/python3.7/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mbroadcast_in_dim\u001b[0;34m(operand, shape, broadcast_dimensions)\u001b[0m\n\u001b[1;32m    705\u001b[0m   return broadcast_in_dim_p.bind(\n\u001b[1;32m    706\u001b[0m       \u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m       broadcast_dimensions=tuple(broadcast_dimensions))\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbroadcast_to_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Archives/Code/pytorch_env/lib/python3.7/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mtop_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_top_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Archives/Code/pytorch_env/lib/python3.7/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Archives/Code/pytorch_env/lib/python3.7/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_in_dim_impl\u001b[0;34m(operand, shape, broadcast_dimensions)\u001b[0m\n\u001b[1;32m   3268\u001b[0m       np.equal(operand.shape, np.take(shape, broadcast_dimensions))):\n\u001b[1;32m   3269\u001b[0m     shape = _broadcast_in_dim_shape_rule(\n\u001b[0;32m-> 3270\u001b[0;31m       operand, shape=shape, broadcast_dimensions=broadcast_dimensions)\n\u001b[0m\u001b[1;32m   3271\u001b[0m     \u001b[0maval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapedArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_expr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Archives/Code/pytorch_env/lib/python3.7/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_in_dim_shape_rule\u001b[0;34m(operand, shape, broadcast_dimensions)\u001b[0m\n\u001b[1;32m   3297\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperand_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m   if any(operand.shape[i] != shape[broadcast_dimensions[i]] and\n\u001b[0;32m-> 3299\u001b[0;31m          operand.shape[i] != 1 for i in range(operand_ndim)):\n\u001b[0m\u001b[1;32m   3300\u001b[0m     msg = (\n\u001b[1;32m   3301\u001b[0m         \u001b[0;34m\"broadcast_in_dim operand dimension sizes must either be 1, or be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for d in range(2, 8):\n",
    "    print('depth {}'.format(d))\n",
    "    err = []\n",
    "    for p in range(5):\n",
    "        dt = RandomizedDT(percent_dimension=1.0, max_depth=d, verbose=False)\n",
    "        r = np.random.permutation(len(x_train))\n",
    "        x_t = x_train[r[0:500],:]\n",
    "        y_t = train_labels[r[0:500]]\n",
    "        x_v = x_val[r[500:550],:]\n",
    "        y_v = train_labels[r[500:550]]\n",
    "        st = time.time()\n",
    "        dt.fit(x_t, y_t)\n",
    "        print('done in {}'.format(time.time() - st))\n",
    "        err.append(zeroOneLoss(dt.predict(x_v), y_v, jnp.ones(len(y_v))))\n",
    "    err = jnp.array(err)\n",
    "    print('mean: {} stddev: {}'.format(err.mean(), err.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Analyze your results in this box_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Next, we want to mitigate the tendancy of decision trees to overfit when the depth is too high and to underfit when the depth is too small by implementing random forests.\n",
    "\n",
    "#### Q3. Code a Random Forest of decision trees, each trained on a subset of the training set. Perform a corase cross-validation to set a reasonnable number of trees (5, 10, 25), percent of training data used (0.5, 0.75), percent of dimensions used (0.5, 0.75, 1.0) and depth (6, 8, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    def __init__(self, nb_trees, percent_dataset=1., percent_dimension=1., max_depth=8):\n",
    "        self.nb_trees = nb_trees\n",
    "        self.percent_dataset = percent_dataset\n",
    "        self.percent_dimension = percent_dimension\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        for t in range(self.nb_trees):\n",
    "            dt = RandomizedDT(percent_dimension=self.percent_dimension, max_depth=self.max_depth)\n",
    "            r = np.random.permutation(len(X))[0:int(self.percent_dataset*len(X))]\n",
    "            dt.fit(X[r,:], y[r])\n",
    "            self.trees.append(dt)\n",
    "        return\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for dt in self.trees:\n",
    "            y.append(dt.predict(X))\n",
    "        y = jax.nn.one_hot(jnp.array(y), num_classes=10)\n",
    "        return y.sum(axis=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(5, 20, 5):\n",
    "    print('nb trees {}'.format(d))\n",
    "    err = []\n",
    "    for p in range(3):\n",
    "        r = np.random.permutation(len(train_data))\n",
    "        x_train = train_data[r[0:500],:]\n",
    "        y_train = train_labels[r[0:500]]\n",
    "        x_val = train_data[r[500:550],:]\n",
    "        y_val = train_labels[r[500:550]]\n",
    "        dt = RandomForest(nb_trees=d, percent_dataset = 0.5, percent_dimension=0.5, max_depth=3)\n",
    "        dt.fit(x_train, y_train)\n",
    "        err.append(zeroOneLoss(dt.predict(x_val), y_val))\n",
    "    err = jnp.array(err)\n",
    "    print('mean: {} stddev: {}'.format(err.mean(), err.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Analyze your results on the full training set in this box*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "To have a more efficient training procedure, we will remove the independance between the trees by using boosting\n",
    "\n",
    "#### Q4. Code the BoostingClassifier that obtains a combination of Randomized Trees using AdaBoost. Each tree is trained using the weighted $0-1$ loss. To allow the tree combination, convert the output of each tree to a one-hot encoded vector. The output of the boosted trees is then the weighted sum of these one-hot vectors and the predicted class is the argmax. Test with the same parameters as the best Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostedTrees():\n",
    "    def __init__(self, nb_trees, percent_dataset=1., percent_dimension=1., max_depth=8):\n",
    "        self.nb_tress = nb_trees\n",
    "        self.percent_dataset = percent_dataset\n",
    "        self.percent_dimension = percent_dimension\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Analyze your results in this box*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5. Perform a similar cross validation as for the Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Analyze your results in this box*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization\n",
    "\n",
    "In order to visualize the decision, we can produce an image the contains only the relevant information with respect to the decisions taken by a tree.\n",
    "\n",
    "#### Q6. For a trained tree, select a leaf and build an image that has a value of 1 for each pixel in the decision path that should be above the threshold, 0 for each pixels in the decision path that should be below the threshold and 0.5 everywhere else. For all classes, show an average all such images for each leaf corresponding to that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Analyze your results in this box*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7. Do the same for the boosted classifier, where the images across trees are averaged using their respective classifier weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
