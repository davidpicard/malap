{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP SVM\n",
    "\n",
    "Save the notebook as either PDF or HTML and make sure all the results are saved correctly (I won't run them and the original format does not save the results automatically), **and put your name in the filename**.\n",
    "\n",
    "<div class=\"alert alert-success\"> \n",
    "<b>Questions are in green boxes.</b>\n",
    "The maximum time you should spend on each question is given as indication only. If you take more time than that, then you should come see me.\n",
    "</div>\n",
    "<div class=\"alert alert-info\" role=\"alert\"><b>Analyzes are in blue boxes.</b> You should comment on your results in theses boxes (Is it good? Is it expected? Why do we get such result? Why is it different from the previous one? etc)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will use the bluebell dataset. It consists of $64\\times 64$ color images, which we will have to flatten into $12k$ dimensional vectors. The code for the dataset comes with several train/val/test splits, but in this notebook, we will use the first split and do our own cross-validation routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "from bluebell import Bluebell\n",
    "X_train_ds = Bluebell('bluebell_64', 'train', split=0)\n",
    "X_val_ds = Bluebell('bluebell_64', 'val', split=0)\n",
    "X_train = np.array([img.flatten()/127.5 - 1. for img, lab in X_train_ds])\n",
    "y_train = np.array([lab for img, lab in X_train_ds])\n",
    "X_val = np.array([img.flatten()/127.5 - 1. for img, lab in X_val_ds])\n",
    "y_val = np.array([lab for img, lab in X_val_ds])\n",
    "plt.imshow(X_train[0].reshape(64, 64, 3)/2+0.5)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce an arbitrary binary classification problem by considering the first 6 classes as the label +1, and the last 6 classes as the label -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bin = X_train\n",
    "y_train_bin = (y_train<6)*2-1\n",
    "X_val_bin = X_val\n",
    "y_val_bin = (y_val<6)*2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we convert the labels to {+1,-1} vectors such that we can process them with one-versus-all binary classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = jnn.one_hot(y_train, num_classes=12)*2-1\n",
    "y_val = jnn.one_hot(y_val, num_classes=12)*2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the 0-1 loss that measures the error rate of a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(y_hat, y):\n",
    "    return (1.!=jnp.sign(y_hat*y)).mean()\n",
    "\n",
    "def multi_error_rate(y_hat, y):\n",
    "    return (1.*(jnp.argmax(y_hat, axis=1) != jnp.argmax(y, axis=1))).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a binary Kernel SVM\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"> <b> Q1.</b> Implement the code of the binary kernel SVM classifier in the following class using Stochastic Dual Coordinate Ascent (SDCA). It has to work for any kernel function like the provided linear kernel I found around 37% error (compared to 50% for random guesses). <i>(Indicative time: about 30 minutes to code, should run in less than 15 seconds if you can the Gram matrix at the begining of training to avoid recomputing each kernel evaluation)</i>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "takes arguements \n",
    "x1: m x d\n",
    "x2: n x d\n",
    "return the Gram matrix m x n\n",
    "'''\n",
    "def LinearKernel(x1, x2):\n",
    "    return jnp.matmul(x1, x2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM():\n",
    "    def __init__(self, X, y, kernel=LinearKernel, C=100.0, epochs=10):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.alpha = None\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "    \n",
    "    '''\n",
    "    x is a matrix nxd of n samples of dimension d\n",
    "    returns a vector of size n containing the prediction of the class\n",
    "    '''\n",
    "    def __call__(self, x):\n",
    "        K = self.kernel(self.X, x)\n",
    "        pred = jnp.dot(self.alpha, K)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try a Linear on the training set reduce to digits 0 and 1 to check that our code works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm = KernelSVM(X_train_bin, y_train_bin, LinearKernel)\n",
    "y_hat = svm(X_val_bin)\n",
    "err = error_rate(y_hat, y_val_bin)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><b>Analyze your results in this box.</b>  Answer\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> <b> Q2.</b> Use cross-validation to find the optimal number of epochs for training, up to a maximum of 25, and the optimal value of $C$. <i>(Indicative time: about 10 minutes to code, less than 10 minutes to run by testing 4 values for C and 4 values for E)</i>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "E = [1, 4, 16, 25]\n",
    "C = [0.01, 0.1, 1, 10, 100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><b>Analyze your results in this box.</b>  Answer\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification\n",
    "\n",
    "Next, we want to perform a multiclass classification using our SVM. We will use the One-versus-All approach where we train a classifier for each class against all others. A test time, we select the class corresponding to the classifier that output the maximum score.\n",
    "\n",
    "<div class=\"alert alert-success\"> <b> Q3.</b>Code a Multi-class SVM using a One-versus-All approach and validate it on the validation set. <i>(Indicative time: about 15 minutes to code, it should run almost as fast as the binary version)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnevsAllKSVM():\n",
    "    def __init__(self, X, y, kernel=LinearKernel, epochs=2, C=1.0):        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.alpha = None\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        \n",
    "                \n",
    "        \n",
    "    def __call__(self, X):\n",
    "        K = self.kernel(X, self.X)\n",
    "        pred = K @ self.alpha\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm = OnevsAllKSVM(X_train, y_train, LinearKernel)\n",
    "y_hat = svm(X_val)\n",
    "err = multi_error_rate(y_hat, y_val)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jnp.argmax(y_hat, axis=1))\n",
    "print(jnp.argmax(y_val, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><b>Analyze your results on the full training set in this box.</b>  Answer\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels\n",
    "\n",
    "A linear classifier is unlikely to be able to classify correctly all classes, we will thus try several different kernels.\n",
    "\n",
    "<div class=\"alert alert-success\"> <b> Q4.</b> Code a class for the Gaussian kernel, the polynomial kernel and the inhomogeneous polynomial kernel, and perform cross-validation to select a kernel and its hyperparameters. <i>(indicative time: about 10 minutes to code per kernel. Should not take significantly more time than the linear kernel, e.g., maximum 30 seconds per run)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussKernel():\n",
    "    def __init__(self, gamma=1.0):\n",
    "        self.gamma = gamma\n",
    "    '''\n",
    "    compute the Gram Matrix\n",
    "    '''\n",
    "    def __call__(self, x1, x2):\n",
    "        return jnp.zeros((x1.shape[0], x2.shape[0]))\n",
    "\n",
    "class PolyKernel():\n",
    "    def __init__(self, d=1.0, c=0.):\n",
    "        self.d = d\n",
    "        self.c = c\n",
    "    '''\n",
    "    compute the Gram Matrix\n",
    "    '''\n",
    "    def __call__(self, x1, x2):\n",
    "        return jnp.zeros((x1.shape[0], x2.shape[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm = OnevsAllKSVM(X_train, y_train, GaussKernel(gamma=0.001))\n",
    "y_hat = svm(X_val)\n",
    "err = multi_error_rate(y_hat, y_val)\n",
    "print(err)\n",
    "\n",
    "svm = OnevsAllKSVM(X_train, y_train, PolyKernel(d=4, c=0.1))\n",
    "y_hat = svm(X_val)\n",
    "err = multi_error_rate(y_hat, y_val)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><b>Analyze your results on the full training set in this box.</b>  Answer\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since support vectors are images we can visualize which training examples were contributing the most to the decision.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"> <b>Q5.</b> For the best performing kernel, visualize the support vectors (limit to the ones with largest absolute weights). <i>(Indicative time: about 10 inutes to code. Should run instanteanously as there is no additional computation)</i></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><b>Analyze your results on the full training set in this box.</b>  Answer\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 dimensionnal visualization\n",
    "\n",
    "In order to visualize the boundaries between the classes, we want to project all data into a 2 dimensional space using PCA, and then perform the classification there.\n",
    "\n",
    "<div class=\"alert alert-success\"> <b>Q6.</b> Implement a trainable kernel that performs a PCA projection followed by a Gaussian kernel and draw a scatter plot of the validation samples along with color coded region of each class using pcolormesh. <i>(Indicative time: may take you more than 30 minutes to code, should run in less than 30 seconds)</i></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAGaussKernel():\n",
    "    def __init__(self, gamma=1.0, d=2):\n",
    "        self.gamma = gamma\n",
    "        self.d = d\n",
    "        self.P = None\n",
    "        self.mu = None\n",
    "    \n",
    "    '''\n",
    "    train self.mu and self.P\n",
    "    '''\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    '''\n",
    "    project examples with self.mu and self.P\n",
    "    '''\n",
    "    def project(self, X):\n",
    "        return (X - self.mu)@self.P\n",
    "    \n",
    "    '''\n",
    "    return the Gram matrix of the projected samples under the Gaussian kernel\n",
    "    '''\n",
    "    def __call__(self, x1, x2, project=True):\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><b>Analyze your results on the full training set in this box.</b>  Answer\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"> <b>Q7 [Optional].</b> Modify your training procedure such that it optimizes all classifiers at each step, instead of training fully each classifier one after another and make a video of the evolution of the prediction boundary  during training. <i>(Indicative time: May very well take you more than an hour of coding and running time can be more than 10 monutes because each iteration has to draw an image)</i></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"><b>Analyze your results on the full training set in this box.</b>  Answer\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
